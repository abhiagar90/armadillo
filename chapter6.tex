\chapter{Amartya Rough}

\section{Entity Resolution}
The basic algorithm of entity resolution goes as follows-

\begin{algorithm}[H]
\KwData{Datasets - S, T }
\KwResult{list -L consisting of proper matches of T in S }
initialization - L is empty \;
parameters - S,T, threshold \;
 \For{all records in t in T}{
  \nl search for t in S \;
  \nl pick records s in S for which match-score(t, s) $\geq$ threshold \;
  \nl append s in L \;
 }
 \caption{Basic Entity Resolution}
\end{algorithm}

Complexity of above algorithm is O(n*m) where n is size(S) and m is size(T) when n records are searched linearly in S.
        From the above, we can find that the two crucial operations here is the choice of proper scoring algorithm to pick s and search of t in S in line [line].

\section{String Matching Algo}
        The requirement of a scoring algorithm was such that it should match words with small spelling mistakes and similar names. In our case, we have used Jaro distance as it considers ranges and transpositions while matching two words. A sample experiment from our side on a list of four names showed the following scores - 
        [[tble]]
        Upon a test run of all algorithms over a sample of 100 names from our datasets we decided to use jaro-winkler for the purpose. We also required to match names which are phonetically similar to other names. These helped us to match names like 'Gautam' and 'Gautambhai', 'Vidya', 'Bidya' and 'Viday' etc.

\section{Comparison techniques}
        As obvious from above algorithm the performance of entity matching algorithm depends largely on how fast the searching occurs in dataset S. A naive algorithm like above added a factor of O(n) on linear search over entire S. The obvious improvement over it is the possible implementation of a binary search to reduce search speed to O(log n) time. But binary search is not applicable here for following two reasons -
            - Binary search uses a predicate like gt, eq, lt , the value of which is true or false. Such predicates determines some order in the dataset. 
            - The absence of such predicates as above avoid any sorting or ranking of the data in any order.
        As a result, the performance of the entire system got bottlenecked by the resolution module. As a result we sought out for other solutions regarding this.

\section{Machine learning techniques}

        After having performance bottleneck in searching records in other datasets, we looked for probabilistic ways of solving the same problem. We used the python library of csvdedupe for this purpose. The library basically induced an active learning mechanism to obtain training samples where it picked two entities of possible match and prompts the user to label positive/negative. It then matches the related entities accordingly with the hypothesis formed. Unfortunately this approach suffered from following drawbacks-
        \begin{itemize}
        \item Too small data to accurately form a proper hypothesis. 
        \item The labels that were asked to mark alongwith data were picked at random and often the results of the algorithm are different in different runs (depending on the number of positive or negative label given at that time).
        \end{itemize}
        Fortunately indexing other dataset helped to come out of this.

\section{Indexing and Apache Solr}
        Indexing allows searching to be very fast of near O(1) speed. Indexes are datastructures that store contents of a document (in our context fields of records in a dataset) for faster access to the document. This enables faster retrieval with a trade off for using more memory. For our purpose we used Apache Solr framework for the searching step.Solr uses Apache Lucene to create an inverted index based desired on fields in the records. An inverted index basically creates a data structure on the content of the records and have pointers to the actual locations of the records. So for all text in the specified fields, Lucene breaks them (tokenizes them) and store them in a data structure for fast retrieval.  Solr also sets up a  Web server with REST APIs to allow us to integrate it with other parts of our system described in chapter [give reference here]. 
        Since Solr has its own sets of protocols we had to modify the way we apply the resolution algorithm described above. The main steps followed by us to realize this are as follows. 

        - Defining a data set to index  (the data set S above). We described a data source which contained the dataset. In this case, it was a mysql database. (file db-data-config.xml) .
        - Defining the fields to index. Solr needs to have a schema of the records to know which fields will indexed and which one is kept as satellite data. These are specified in solr configuration files. (schema.xml)
        - Defining how to preprocess all the terms before creating the index. Solr allows to specify a list of pre-built tokenizers, stemmers, filters to preprocess a term or custom ones if necessary. We used whitespace tokenizers and double metaphone phonetic filters to get a match score relevant to our purpose and in this way used the phonetic algorithm for better text matching. (file - solrconfig.xml)
        - Forming a lucene query based on the contents of records of another dataset (data set T above)
        - Applying Jaro algorithm for comparison was difficult in Solr. This is because, all the functions applied to the text for indexing are necessarily single parameter. Jaro or any other non-phonetic string metric needs at lest two string Results returned by the Solr is further filtered by the Jaro-Winkler algorithm. Results being quite small, does not take much time even if a one-one matching algo is executed. 

\subsection{Solr Fields}
    To effectively triangulate two entities, special emphasis was given on which fields to compare while doing it. After few experiments we decided to match records on following fields generated from the graph data model we discussed in previous section.

    - Aliases - a list that contains names pertaining to an entity. This is especially required when a person/institution is known by several names in the world. Eg. - Narendra Modi vs Narendra Damodar Modi, BJP vs Bharatiya Janata Party 
    - Aliases Phonetic - same as above but here search is done on phonetic index.
    - label - Label dictates the type of entity as per data model in chapter [refer chapter here].
    - Keywords - a list that contains main keywords of the entity. This field is most helpful in triangulation as it indexes all the properties of the entity and the aliases of the entities directly related with the original. Important properties unique to a particular entity like location for a particular item.

\subsection{Lucene Queries}
    Proper search queries are essential to effeciently resolve an entity. These involved using above fields effectively to obtain relevant entities- 
    The grammar of the lucene query used by us goes as follows-

    L:= I:(Q) AND L OR epsilon

    where I is the index field (one of above) and Q is the query string to be matched against I
    Where index field is one of the above and query string can be as follows -
    "string text" - matching the exact word 'string text'
    string text - matches string or text or both
    string~ - lucene applies edit distance to string and returns the possible matches

    The query we used for our purpose is as follows-
    " labels:(each label separated by whitespace) aliases:(each alias~ separated by whitespace ) AND aliases-phonetic:(each alias separated by whitepace) AND keywords:( each keyword~ separated by whitespace)"

    Eg. - 
\subsection{Performance}
    On testing our Solr integrated system with the original basic resolution algorithm, we found many fold improvements. Initially upon resolving 1000 corporate entities against about 500 political ones over the "name" field in both took us about 150 minutes to resolve. That makes resolution of a single entity about 18s.
    Compared to that, a single entity is resolved in Solr in little over 1s showing a performance upgrade of about 18x.



\section{Admin}
admin:
delete index
refresh index
eleveate users
verfier contributions
bots


\section{End user}
end users:
read profiles
see connections
cypher read query - explain - etc.
limit automatically
viz
provenance view
sign up\\


